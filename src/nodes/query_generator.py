"""
Query Generator Node
ì£¼ì œë¥¼ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ë…¸ë“œ
"""

import json
from typing import Dict, List
from ..research_state import ResearchState
from ..utils.llm_config import get_llm
from langchain_core.prompts import ChatPromptTemplate


def generate_queries(state: ResearchState) -> Dict:
    """
    ë°˜ë³µ íšŸìˆ˜ì— ë”°ë¼ ì°¨ë³„í™”ëœ ê²€ìƒ‰ ì „ëµ ì ìš©
    
    ì „ëµ:
    - 1ì°¨: í¬ê´„ì  ê²€ìƒ‰ (ê°œë…+í˜„í™©+ë°ì´í„°+ì‚¬ë¡€+ì´ìŠˆ ëª¨ë‘ í¬í•¨)
    - 2ì°¨: ë¶€ì¡±í•œ ì •ë³´ ë³´ì™„ (Info Evaluator í”¼ë“œë°± ê¸°ë°˜)
    - 3ì°¨: ì¶”ê°€ ì‹¬í™” (ì—¬ì „íˆ ë¶€ì¡±í•œ ë¶€ë¶„ ë§ˆë¬´ë¦¬)
   """

    iteration = state.get("iteration_count", 0)
    # existing_results = state.get("search_results", [])
    # existing_titles = []
    # for res in existing_results[-10:]: 
    #   existing_titles.append(res.get("title"))

    print(f"\n[Query Generator] Step {iteration + 1} ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘...")

    if iteration == 0:
      result = generate_overview_queries(state)
    
    elif iteration == 1:
      result = generate_data_queries(state)

    else:
      result = generate_analysis_queries(state)   

    return {
        **result,
        "iteration_count": iteration + 1
    }


def generate_overview_queries(state: ResearchState) -> Dict:  
   """
   1ì°¨ í¬ê´„ì  ê²€ìƒ‰
   """

   topic = state["topic"]
   llm = get_llm(temperature=0.7)

   prompt = ChatPromptTemplate.from_messages([
      ("system", "ë‹¹ì‹ ì€ ì£¼ì œì˜ ì„±ê²©ì„ ë¶„ì„í•´ ì ì ˆí•œ ê²€ìƒ‰ ì „ëµì„ ìˆ˜ë¦½í•˜ê³ , "
        "ë¦¬ì„œì¹˜ì— íš¨ê³¼ì ì¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
       ("user", """
            ì£¼ì œ: {topic}
        
            ë¨¼ì €, ìœ„ ì£¼ì œê°€ ë‹¤ìŒ ì¤‘ ì–´ëŠ ë²”ìœ„ê°€ ë” ì ì ˆí•œì§€ íŒë‹¨í•˜ì„¸ìš”.
              - local: êµ­ë‚´ ì •ì±…, ì œë„, ê¸°ì—…, í•œêµ­ ì‹œì¥ ì¤‘ì‹¬ì˜ ì£¼ì œ
              - global: êµ­ì œ ë™í–¥, í•™ìˆ /ê¸°ìˆ  ì—°êµ¬, ê¸€ë¡œë²Œ ì‚°ì—… í‘œì¤€ì´ ì¤‘ìš”í•œ ì£¼ì œ
              ê·¸ íŒë‹¨ì„ ë°”íƒ•ìœ¼ë¡œ, ìœ„ ì£¼ì œë¥¼ ë¦¬ì„œì¹˜í•˜ê¸° ìœ„í•œ ì´ˆê¸° ê²€ìƒ‰ ì¿¼ë¦¬ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        
            [ê²€ìƒ‰ ë²”ìœ„ ê·œì¹™]:
              - localë¡œ íŒë‹¨í•œ ê²½ìš°: í•œêµ­ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ 3ê°œ ìƒì„±
              - globalë¡œ íŒë‹¨í•œ ê²½ìš°: í•œêµ­ì–´ ì¿¼ë¦¬ 1ê°œ + ì˜ì–´(English) ì¿¼ë¦¬ 2ê°œ ìƒì„±
            
            [ì¿¼ë¦¬ ì‘ì„± ì§€ì¹¨]
              - 1ì°¨ ê²€ìƒ‰ë§Œìœ¼ë¡œë„ ê¸°ë³¸ì ì¸ ë¦¬í¬íŠ¸ ì‘ì„±ì´ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.
              - ê° ì¿¼ë¦¬ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì„ ë‹´ë‹¹í•´ì•¼ í•©ë‹ˆë‹¤.
                1. ê°œë…/ì •ì˜ì™€ ìµœì‹  í˜„í™©
                2. í†µê³„/ë°ì´í„°ì™€ ì ìš© ì‚¬ë¡€
                3. ì£¼ìš” ì´ìŠˆì™€ ë¯¸ë˜ ì „ë§
            
            [ì¶œë ¥ í˜•ì‹]
              ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
              ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

              {{
                "search_scope": "local" | "global",
                "search_queries": [
                  "query 1",
                  "query 2",
                  "query 3"
                ]}}
        """)
   ])
   # pipe ì—°ì‚°ìë¡œ promptì™€ llm ì—°ê²°
   chain = prompt | llm
   response = chain.invoke({ "topic": topic})
   data = parse_json_response(response.content)

   if data.get("search_scope") not in ("local", "global"):
      raise ValueError("search_scopeì´ ì •í•´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
  
   return {
      "search_scope": data["search_scope"],
      "search_queries": data["search_queries"]
   } 


def generate_data_queries(state: ResearchState) -> Dict: 
  """
    2ì°¨ Info Evaluator í”¼ë“œë°± ê¸°ë°˜ ë³´ì™„    
    ëª©í‘œ:
    - ë¶€ì¡±í•œ ì •ë³´ ì§ì ‘ ë³´ì™„
    - ì¶”ì²œ í‚¤ì›Œë“œ ê²€ì¦ í›„ í™œìš©
   """
   
  topic = state["topic"]
  search_scope = state.get("search_scope", "")
  iteration = state.get("iteration_count", 0)
  missing_info = state.get("missing_info", "")
  recommended_keywords = state.get("recommended_keywords", "")

  llm = get_llm(temperature=0.5) 
  prompt = ChatPromptTemplate.from_messages([
     ("system", "ë‹¹ì‹ ì€ ì£¼ì œì— ë§ëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
     ("user", """
        ì£¼ì œ: {topic}
        ê²€ìƒ‰ ë²”ìœ„: {search_scope} ìœ ì§€
          - local: í•œêµ­ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ 3ê°œ ìƒì„±
          - global: í•œêµ­ì–´ ì¿¼ë¦¬ 1ê°œ + ì˜ì–´(English) ì¿¼ë¦¬ 2ê°œ ìƒì„±
        
        í˜„ì¬ {iteration}ë²ˆì§¸ ê²€ìƒ‰ ì‹œë„ì´ë¯€ë¡œ ì „ë³´ë‹¤ ë”ìš± êµ¬ì²´ì ì´ê³  ì •ë°€í•œ ì¿¼ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
      
        [ì¬ê²€ìƒ‰ ê°€ì´ë“œ]
        1. ë¶€ì¡±í•œ ì •ë³´: {missing_info}
        2. ì¶”ì²œ ê²€ìƒ‰ í‚¤ì›Œë“œ: {recommended_keywords}
        
        [ì§€ì¹¨]
        1. [í•„ìˆ˜] ê²€ìƒ‰ ë²”ìœ„({search_scope})ì— ë”°ë¥¸ ì–¸ì–´ ê·œì¹™ì„ ìµœìš°ì„ ìœ¼ë¡œ ì¤€ìˆ˜í•˜ì„¸ìš”.
          - local: ì¿¼ë¦¬ 3ê°œ ëª¨ë‘ í•œêµ­ì–´ë¡œ ì‘ì„±  
          - global: 1ë²ˆ ì¿¼ë¦¬ëŠ” í•œêµ­ì–´, 2ë²ˆê³¼ 3ë²ˆ ì¿¼ë¦¬ëŠ” ë°˜ë“œì‹œ ì˜ì–´(English)ë¡œ ì‘ì„±
        2. ì¶”ì²œ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ì£¼ì œ{topic}ì™€ ì¶©ë¶„íˆ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”.
        3. ì£¼ì œì™€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆëŠ” í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ì„ ë³„í•˜ì—¬, {missing_info}ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆëŠ” ì •ë°€ ì¿¼ë¦¬ 3ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
        4. {recommended_keywords}ê°€ ì£¼ì œì™€ ë§ì§€ ì•ŠëŠ”ë‹¤ê³  íŒë‹¨ë˜ë©´, ì£¼ì œì˜ ë§¥ë½ì— ë§ëŠ” ë” ì ì ˆí•œ ì „ë¬¸ ìš©ì–´ë¥¼ ì§ì ‘ ì„ ì •í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.
        5. ì´ë¯¸ ìˆ˜ì§‘ëœ ìë£Œì™€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
      
        [ì¶œë ¥ í˜•ì‹]
          ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
          íŠ¹íˆ global ë²”ìœ„ì¼ ê²½ìš°, 2~3ë²ˆ ì¿¼ë¦¬ëŠ” í•´ì™¸ ìë£Œ ê²€ìƒ‰ìš© ì˜ì–´ì—¬ì•¼ í•©ë‹ˆë‹¤.
          ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

          {{
            "search_scope": "local" | "global",
            "search_queries": [
              "í•œêµ­ì–´ ì¿¼ë¦¬ (ì£¼ë¡œ êµ­ë‚´ í˜„í™©)",
              "English search query (Global data/trends)",
              "English search query (Technical/Academic details)"
            ]}}
      """)
  ])

  chain = prompt | llm
  response = chain.invoke({
    "topic": topic,
    "search_scope": search_scope,
    "iteration": iteration,
    "missing_info": missing_info,
    "recommended_keywords": ", ".join(recommended_keywords) if recommended_keywords else "ì—†ìŒ"
  })

  data = parse_json_response(response.content)
  
  return {"search_queries": data["search_queries"]}


def generate_analysis_queries(state: ResearchState) -> Dict:
  """
  3ì°¨ ë§ˆì§€ë§‰ ì‹¬í™” ë° ìµœì¢… ë³´ì™„
  """

  topic = state["topic"]
  search_scope = state.get("search_scope", "")
  iteration = state.get("iteration_count", 0)
  missing_info = state.get("missing_info", "")
  recommended_keywords = state.get("recommended_keywords", "")

  llm = get_llm(temperature=0.3) 
  prompt = ChatPromptTemplate.from_messages([
     ("system", "ë‹¹ì‹ ì€ ë¦¬ì„œì¹˜ ê°­ì„ ì™„ì „íˆ í•´ê²°í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
     ("user", """
        ì£¼ì œ: {topic}
        ê²€ìƒ‰ ë²”ìœ„: {search_scope} ìœ ì§€
          - local: í•œêµ­ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ 3ê°œ ìƒì„±
          - global: í•œêµ­ì–´ ì¿¼ë¦¬ 1ê°œ + ì˜ì–´(English) ì¿¼ë¦¬ 2ê°œ ìƒì„±
        
        í˜„ì¬ {iteration}ë²ˆì§¸ ê²€ìƒ‰ ì‹œë„ì´ë¯€ë¡œ ì „ë³´ë‹¤ ë”ìš± êµ¬ì²´ì ì´ê³  ì •ë°€í•œ ì¿¼ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
      
        [ì¬ê²€ìƒ‰ ê°€ì´ë“œ]
          1. ë¶€ì¡±í•œ ì •ë³´: {missing_info}
          2. ì¶”ì²œ ê²€ìƒ‰ í‚¤ì›Œë“œ: {recommended_keywords}
        
        [ì§€ì¹¨]
          1. [í•„ìˆ˜] ê²€ìƒ‰ ë²”ìœ„({search_scope})ì— ë”°ë¥¸ ì–¸ì–´ ê·œì¹™ì„ ìµœìš°ì„ ìœ¼ë¡œ ì¤€ìˆ˜í•˜ì„¸ìš”.
            - local: ì¿¼ë¦¬ 3ê°œ ëª¨ë‘ í•œêµ­ì–´ë¡œ ì‘ì„±  
            - global: 1ë²ˆ ì¿¼ë¦¬ëŠ” í•œêµ­ì–´, 2ë²ˆê³¼ 3ë²ˆ ì¿¼ë¦¬ëŠ” ë°˜ë“œì‹œ ì˜ì–´(English)ë¡œ ì‘ì„±
          2. ì¶”ì²œ ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ì£¼ì œ{topic}ì™€ ì¶©ë¶„íˆ ì—°ê´€ë˜ì–´ ìˆëŠ”ì§€ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”.
          3. ì£¼ì œì™€ ë°€ì ‘í•œ ê´€ë ¨ì´ ìˆëŠ” í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ ì„ ë³„í•˜ì—¬, {missing_info}ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆëŠ” ì •ë°€ ì¿¼ë¦¬ 3ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
          4. {recommended_keywords}ê°€ ì£¼ì œì™€ ë§ì§€ ì•ŠëŠ”ë‹¤ê³  íŒë‹¨ë˜ë©´, ì£¼ì œì˜ ë§¥ë½ì— ë§ëŠ” ë” ì ì ˆí•œ ì „ë¬¸ ìš©ì–´ë¥¼ ì§ì ‘ ì„ ì •í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.
          5. ì´ë¯¸ ìˆ˜ì§‘ëœ ìë£Œì™€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì „ë¬¸ì ì´ê³  êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
        
        [ì „ëµ]
          - í•™ìˆ  ë…¼ë¬¸, ì „ë¬¸ ë³´ê³ ì„œ, ì •ë¶€ ìë£Œ ë“± ê¶Œìœ„ ìˆëŠ” ì¶œì²˜ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ
          - êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ë°ì´í„°, ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ì¿¼ë¦¬
          - ì „ë¬¸ ìš©ì–´ì™€ í‚¤ì›Œë“œë¥¼ ì ê·¹ í™œìš©
      
        [ì¶œë ¥ í˜•ì‹]
          ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
          íŠ¹íˆ global ë²”ìœ„ì¼ ê²½ìš°, 2~3ë²ˆ ì¿¼ë¦¬ëŠ” í•´ì™¸ ìë£Œ ê²€ìƒ‰ìš© ì˜ì–´ì—¬ì•¼ í•©ë‹ˆë‹¤.
          ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

          {{
            "search_scope": "local" | "global",
            "search_queries": [
              "í•œêµ­ì–´ ì¿¼ë¦¬ (ì£¼ë¡œ êµ­ë‚´ í˜„í™©)",
              "English search query (Global data/trends)",
              "English search query (Technical/Academic details)"
            ]}}
      """)
  ])

  chain = prompt | llm
  response = chain.invoke({
    "topic": topic,
    "search_scope": search_scope,
    "iteration": iteration,
    "missing_info": missing_info,
    "recommended_keywords": ", ".join(recommended_keywords) if recommended_keywords else "ì—†ìŒ"
  })

  data = parse_json_response(response.content)
  return {"search_queries": data["search_queries"]}
  

# LLM ì‘ë‹µ jsonìœ¼ë¡œ íŒŒì‹±
def parse_json_response(content: str) -> Dict:
    content = content.replace("```json", "").replace("```", "").strip()
    try:
      data = json.loads(content)    
    except json.JSONDecodeError:
       raise ValueError("ì‘ë‹µì´ json í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
    
    if "search_queries" not in data:
       raise ValueError("search_queriesê°€ ì‘ë‹µì— ì—†ìŠµë‹ˆë‹¤.")
    
    if not isinstance(data["search_queries"], list):
       raise ValueError("search_queriesëŠ” list í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    return data


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":    
    test_topic = "ì¸ê³µì§€ëŠ¥ì„ í™œìš©í•œ ì˜ë£Œ ì§„ë‹¨ì˜ ìµœì‹  ë™í–¥"
    
    # 1ì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n[1ì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸]")
    state_1 = {
        "topic": test_topic,
        "iteration_count": 0
    }
    result_1 = generate_queries(state_1)

    print(f"âœ… Search Scope: {result_1.get('search_scope')}")
    print(f"âœ… ê²€ìƒ‰ ì¿¼ë¦¬:")
    for i, query in enumerate(result_1.get('search_queries', []), 1):
        print(f"   {i}. {query}")
    
    # 2ì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n[2ì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸]")
    state_2 = {
        "topic": test_topic,
        "search_scope": result_1.get("search_scope"),
        "iteration_count": 1,
        "missing_info": "êµ¬ì²´ì ì¸ ì‹œì¥ ê·œëª¨ í†µê³„ ë¶€ì¡±",
        "recommended_keywords": ["AI ì˜ë£Œ ì‹œì¥", "ë§¤ì¶œ í˜„í™©"]
    }
    result_2 = generate_queries(state_2)
    print(f"âœ… Search Scope: {state_2.get('search_scope')} (ìœ ì§€)")
    print(f"âœ… ê²€ìƒ‰ ì¿¼ë¦¬:")
    for i, query in enumerate(result_2.get('search_queries', []), 1):
        print(f"   {i}. {query}")
    
    # 3ì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n[3ì°¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸]")
    state_3 = {
        "topic": test_topic,
        "search_scope": result_1.get("search_scope"),
        "iteration_count": 2,
        "missing_info": "êµ­ë‚´ ë³‘ì› ë„ì… ì‚¬ë¡€ ë° ê·œì œ í˜„í™© ë¶€ì¡±",
        "recommended_keywords": ["ì„œìš¸ëŒ€ë³‘ì›", "ì‚¼ì„±ë³‘ì›", "AI ê·œì œ"]
    }
    result_3 = generate_queries(state_3)
    print(f"âœ… Search Scope: {state_3.get('search_scope')} (ìœ ì§€)")
    print(f"âœ… ê²€ìƒ‰ ì¿¼ë¦¬:")
    for i, query in enumerate(result_3.get('search_queries', []), 1):
        print(f"   {i}. {query}")
    
    # ===== ì „ì²´ ê²°ê³¼ ë¹„êµ =====
    print("\n" + "=" * 60)
    print("ğŸ“Š ì „ì²´ ê²°ê³¼ ë¹„êµ")
    print("=" * 60)
    print(f"1ì°¨ (ê°œìš”): {result_1.get('search_queries')}")
    print(f"2ì°¨ (ë°ì´í„°): {result_2.get('search_queries')}")
    print(f"3ì°¨ (ì‹¬í™”): {result_3.get('search_queries')}")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
