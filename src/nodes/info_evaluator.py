"""
Information Evaluator Node
ìˆ˜ì§‘ëœ ì •ë³´ì˜ ì¶©ë¶„ì„±ì„ í‰ê°€í•˜ëŠ” ë…¸ë“œ
"""


from ..research_state import ResearchState
from ..utils.llm_config import get_llm
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
import json

def evaluate_information(state: ResearchState) -> dict:
    """
    LLMì´ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ë¦¬í¬íŠ¸ ì‘ì„±ì— ì¶©ë¶„í•œì§€ í‰ê°€í•©ë‹ˆë‹¤.

    í‰ê°€ ê¸°ì¤€:
    - ê²€ìƒ‰ ê²°ê³¼ê°€ 6ê°œ ì´ìƒ OR
    - ë°˜ë³µ íšŸìˆ˜ê°€ 2íšŒ ì´ìƒ
    - TOPICê³¼ì˜ ì—°ê´€ì„±
    """

    topic = state["topic"]
    search_scope = state.get("search_scope", "")
    search_results = state.get("search_results", [])
    iteration_count = state.get("iteration_count", 0)
    
    print(f"\n[Info Evaluator] ì •ë³´ ì¶©ë¶„ì„± í‰ê°€ ì¤‘... (ë°˜ë³µ: {iteration_count})")

    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    if search_results:
        total = sum(r.get("trust_score", 0) for r in search_results)
        avg_trust = total / len(search_results)
        print(f"  í‰ê·  ì‹ ë¢°ë„: {avg_trust:.2f}")
    else:
        avg_trust = 0.0    

    # ìµœì†Œ ì¡°ê±´ ì²´í¬
    if len(search_results) < 6:
        return { "evaluation": "insufficient", "evaluation_reason": "ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}

    if iteration_count < 2:
        return { "evaluation": "insufficient", "evaluation_reason": "ë°˜ë³µ íšŸìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}
    
    if avg_trust < 0.5:
      print(f"  í‰ê·  ì‹ ë¢°ë„ ë¶€ì¡±: {avg_trust:.2f}")
      return { "evaluation": "insufficient", "evaluation_reason": "ì‹ ë¢°ë„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}
    
    if high_trust_count := len([r for r in search_results if r.get("trust_score", 0) >= 0.7]) < 2:
      print(f"  ê³ ì‹ ë¢° ì¶œì²˜ ë¶€ì¡±: {high_trust_count}ê°œ")
      return { "evaluation": "insufficient", "evaluation_reason": "ê³ ì‹ ë¢° ì¶œì²˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."}

    # LLM ì´ˆê¸°í™” (ë‚´ìš© í‰ê°€ìš©)
    llm = get_llm(temperature=0.3)

    # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í›„ LLMì—ê²Œ í‰ê°€ ìš”ì²­
    results_summary = "\n".join(
        f"[{index+1}] [ì‹ ë¢°ë„: {result.get('trust_score', 0):.2f}] {result.get('title', 'No Title')}\n"
        f"{result.get('content', '')[:200]}..."
        for index, result in enumerate(search_results[:10])
    )

    # í‰ê°€ í”„ë¡¬í”„íŠ¸ ì‘ì„±
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ í•œêµ­ì–´ì™€ ì˜ì–´ ìë£Œì˜ í’ˆì§ˆì„ í†µí•©ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ê¸€ë¡œë²Œ ë¦¬ì„œì¹˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
            "ìˆ˜ì§‘ëœ ìë£Œê°€ ì£¼ì œì— ëŒ€í•´ ì‹¬ì¸µ ë¦¬í¬íŠ¸ë¥¼ ì“°ê¸°ì— ì§ˆì ìœ¼ë¡œ ì¶©ë¶„í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”."
            "íŠ¹íˆ ê¸°ìˆ ì  ì„¸ë¶€ ì‚¬í•­ì´ë‚˜ ê¸€ë¡œë²Œ í†µê³„ëŠ” ì˜ì–´ê¶Œ ì „ë¬¸ ì¶œì²˜(Nature, IEEE, TechCrunch ë“±)ì˜ ìë£Œë¥¼ ë§¤ìš° ë†’ê²Œ í‰ê°€í•˜ì‹­ì‹œì˜¤."),
        ("user", """
            ì£¼ì œ: {topic}
            ê²€ìƒ‰ ë²”ìœ„: {search_scope}
            ìˆ˜ì§‘ëœ ê²€ìƒ‰ ê²°ê³¼ ({search_count}ê°œ, í‰ê·  ì‹ ë¢°ë„: {avg_trust}):{results_summary}

            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë¦¬í¬íŠ¸ ì‘ì„±ì— ì¶©ë¶„í•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.
            
            ì°¸ê³ :
            - í‰ê·  ì‹ ë¢°ë„ {avg_trust} ëŠ” ì´ë¯¸ ê²€ì¦ë¨
            - ê³ ì‹ ë¢° ì¶œì²˜(0.7+)ë¥¼ ì£¼ìš” ê·¼ê±°ë¡œ ìš°ì„ 
            - ì¤‘ì‹ ë¢° ì¶œì²˜(0.3~0.6)ëŠ” ë³´ì¡° ìë£Œë¡œ í™œìš©
            - ì €ì‹ ë¢° ì¶œì²˜ë§Œ ìˆìœ¼ë©´ insufficient

            ë¨¼ì € ê° ìë£Œë¥¼ ê°„ë‹¨íˆ í‰ê°€í•´ì£¼ì„¸ìš”. 
            
            í‰ê°€ í•­ëª©:
            - ì£¼ì œ ê´€ë ¨ì„±(relevance): high, medium, low
            - êµ¬ì²´ì ì¸ ë°ì´í„°ì˜ ìœ ë¬´(quality): high, medium, low
            - í•œì¤„ í‰ê°€(comment)

            ê·¸ëŸ° ë‹¤ìŒ, ì „ì²´ì ì¸ ì •ë³´ì˜ ì¶©ë¶„ì„±ì„ íŒë‹¨í•´ì£¼ì„¸ìš”.

            í‰ê°€ ê¸°ì¤€:
            1. ê³ ì‹ ë¢° ì¶œì²˜ê°€ 2ê°œ ì´ìƒì¸ê°€?
            2. ì£¼ì œ-ë‚´ìš© ì¼ì¹˜ë„: ê° ìë£Œê°€ ì£¼ì œì™€ ì§ì ‘ ê´€ë ¨ ìˆëŠ”ê°€?
            3. ì •ë³´ êµ¬ì²´ì„±: ë°ì´í„°, í†µê³„, ì‚¬ë¡€ ë“± êµ¬ì²´ì  ì •ë³´ê°€ ìˆëŠ”ê°€?
            4. ì •ë³´ ì¼ê´€ì„±: ì—¬ëŸ¬ ì¶œì²˜ê°€ ëª¨ìˆœë˜ì§€ ì•ŠëŠ”ê°€? 
            5. ë¶€ì¡±í•œ ì •ë³´: ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ëŠ”?

            ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
            {{
                "individual_reviews": [
                    {{
                        "index": ìë£Œ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘),
                        "relevance": "high/medium/low",
                        "quality": "high/medium/low",
                        "comment": "í•œì¤„ í‰ê°€"
                    }}
                ],
                "is_sufficient": true ë˜ëŠ” false,
                "reason": "í‰ê°€ ì´ìœ ",
                "missing_info": "ë¶€ì¡±í•œ ì •ë³´ (ìˆë‹¤ë©´)",
                "recommended_keywords": "ì¶”ê°€ ê²€ìƒ‰ì´ í•„ìš”í•œ í‚¤ì›Œë“œ (ìˆë‹¤ë©´)"
            }}
        """)
        ])
    
    # í‰ê°€ ì‹¤í–‰
    chain = prompt | llm
    response = chain.invoke({
        "topic": topic,
        "search_scope": search_scope,
        "results_summary": results_summary,
        "search_count": len(search_results),
        "avg_trust": f"{avg_trust:.2f}"
        })
    
    # ì‘ë‹µ íŒŒì‹±
    try:
        content = response.content if hasattr(response, 'content') else str(response)
        # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°)
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
        
        evaluation = json.loads(content.strip())
        is_sufficient = evaluation.get("is_sufficient", False)
        reason = evaluation.get("reason", "")
        individual_reviews = evaluation.get("individual_reviews", "")

        print(f"\n[ìë£Œë³„ í‰ê°€]\n{individual_reviews}")
        print(f"\n[ì¢…í•© í‰ê°€]")
        print(f"  í‰ê°€ ê²°ê³¼: {'ì¶©ë¶„' if is_sufficient else 'ë¶€ì¡±'}")
        print(f"  ì´ìœ : {reason}")

        if not is_sufficient:
            print(f"  ë¶€ì¡±í•œ ì •ë³´: {evaluation.get('missing_info', 'N/A')}")
            print(f"  ì¶”ì²œ í‚¤ì›Œë“œ: {evaluation.get('recommendation', 'N/A')}")
        
        return {
            "evaluation": "sufficient" if is_sufficient else "insufficient",
            "evaluation_reason": reason,
            "missing_info": evaluation.get("missing_info"),
            "recommended_keywords": evaluation.get("recommended_keywords")
        }
        
    except Exception as e:
        print(f"  âš ï¸ í‰ê°€ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë¡œì§ìœ¼ë¡œ í´ë°±
        if len(search_results) >= 6 or iteration_count >= 3:
            return {
                "evaluation": "sufficient",
                "evaluation_reason": "ê¸°ë³¸ ì¡°ê±´ ì¶©ì¡±"
            }
        else:
            return {
                "evaluation": "insufficient", 
                "evaluation_reason": "ìë£Œ ë¶€ì¡±"
            }

    # result_count = len(search_results)

    # print(f"\n[Info Evaluator] ì •ë³´ ì¶©ë¶„ì„± í‰ê°€ ì¤‘...")
    # print(f"  ìˆ˜ì§‘ëœ ìë£Œ: {result_count}ê°œ")
    # print(f"  ë°˜ë³µ íšŸìˆ˜: {iteration_count}íšŒ")

    # # ì¡°ê±´ ì²´í¬
    # if result_count >= 6 or iteration_count >= 2:
    #     print(f"  ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ â†’ ë¦¬í¬íŠ¸ ìƒì„±")
    # else:
    #     print(f"  ì¶”ê°€ ê²€ìƒ‰ í•„ìš”")

    # # Stateë¥¼ ë³€ê²½í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¹ˆ dict ë°˜í™˜
    # return {}


def should_continue(state: ResearchState) -> str:
    """
    LLM í‰ê°€ì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ - ì—£ì§€ 

    Returns:
        "generate_report" ë˜ëŠ” "search_more"
    """
    # search_results = state.get("search_results", [])
    evaluation = state.get("evaluation", "")
    iteration_count = state.get("iteration_count", 0)


    if evaluation == "sufficient" or iteration_count >= 3:
        print(f"--- ì •ë³´ê°€ ì¶©ë¶„í•˜ê±°ë‚˜ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ---")
        return "generate_report"
    else:
        print(f"--- ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¶”ê°€ ê²€ìƒ‰ì„ ì§„í–‰í•©ë‹ˆë‹¤. ---")
        return "search_more"

# ê²€ì¦ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    from ..research_state import ResearchState

    # 1. ê¸€ë¡œë²Œ ë¦¬ì„œì¹˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ (ì¶©ë¶„í•œ ì •ë³´ ì‹œë‚˜ë¦¬ì˜¤)
    print("\n" + "="*60)
    print("ğŸŒ [Test 1] ê¸€ë¡œë²Œ ë¦¬ì„œì¹˜ ì •ë³´ ì¶©ë¶„ì„± í‰ê°€")
    print("="*60)

    test_state = {
        "topic": "ì¸ê³µì§€ëŠ¥(AI) ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ê¸°ìˆ ì˜ ê¸€ë¡œë²Œ ë™í–¥",
        "search_scope": "global",  # ê¸€ë¡œë²Œ ë²”ìœ„ ì„¤ì •
        "iteration_count": 2,      # 2íšŒì°¨ ë°˜ë³µ
        "search_results": [
            {
                "title": "[Global] AI in Medical Imaging: Market Trends 2024", 
                "url": "https://www.nature.com/articles/ai-health", 
                "content": "The global market for AI in medical imaging is expected to grow at a CAGR of 35%. Current focus is on early cancer detection using transformer-based models...", 
                "trust_score": 0.9
            },
            {
                "title": "[Global] IEEE: Deep Learning for Clinical Diagnosis", 
                "url": "https://ieeexplore.ieee.org/document/12345", 
                "content": "We propose a new multi-modal AI framework for early diagnosis. Performance benchmarks show 98% accuracy in localized datasets...", 
                "trust_score": 0.9
            },
            {
                "title": "êµ­ë‚´ AI ì˜ë£Œê¸°ê¸° ì¸í—ˆê°€ ê°€ì´ë“œë¼ì¸", 
                "url": "https://gov.kr/report/medical-ai", 
                "content": "ì‹ì•½ì²˜ëŠ” 2024ë…„ AI ì˜ë£Œê¸°ê¸° ì†Œí”„íŠ¸ì›¨ì–´ì— ëŒ€í•œ ìƒˆë¡œìš´ ì‹¬ì‚¬ ê°€ì´ë“œë¥¼ ë°œí‘œí•¨. êµ­ë‚´ ê¸°ì—…ì˜ ê¸€ë¡œë²Œ ì§„ì¶œ ì§€ì› ë°©ì•ˆ í¬í•¨...", 
                "trust_score": 1.0
            },
            {
                "title": "ë£¨ë‹›-ë·°ë…¸ ë“± êµ­ë‚´ AI ì˜ë£Œ ì§„ë‹¨ ê¸°ì—… í•´ì™¸ ì„±ê³¼", 
                "url": "https://news.naver.com/tech/health-ai", 
                "content": "êµ­ë‚´ ì£¼ìš” AI ì˜ë£Œ ê¸°ì—…ë“¤ì´ ë¯¸êµ­ FDA ìŠ¹ì¸ì„ ì‡ë”°ë¼ íšë“í•˜ë©° ê¸€ë¡œë²Œ ì‹œì¥ ì ìœ ìœ¨ì„ í™•ëŒ€ ì¤‘...", 
                "trust_score": 0.8
            },
            {
                "title": "AI ìœ¤ë¦¬ ë° ì˜ë£Œ ë°ì´í„° ë³´ì•ˆ ì´ìŠˆ", 
                "url": "https://example.com/ethics-ai", 
                "content": "Patient data privacy remains a key challenge for AI implementation in hospitals...", 
                "trust_score": 0.5
            },
            {
                "title": "Future of AI in Diagnostics", 
                "url": "https://techcrunch.com/future-ai", 
                "content": "Future perspectives on decentralized AI and federated learning in healthcare...", 
                "trust_score": 0.75
            },
        ]
    }

    # í‰ê°€ ì‹¤í–‰
    eval_result = evaluate_information(test_state)

    print("\n" + "-"*60)
    print(f"âœ… ë¦¬ì„œì¹˜ ì£¼ì œ: {test_state['topic']}")
    print(f"âœ… ê²€ìƒ‰ ë²”ìœ„: {test_state['search_scope']}")
    print(f"âœ… ìˆ˜ì§‘ ìë£Œ ìˆ˜: {len(test_state['search_results'])}ê°œ")
    
    print("\n[ìµœì¢… í‰ê°€ ê²°ê³¼]")
    print(f"ğŸ“ ìƒíƒœ: {eval_result.get('evaluation')}")
    print(f"ğŸ“ ì´ìœ : {eval_result.get('evaluation_reason')}")
    
    if eval_result.get('evaluation') == "insufficient":
        print(f"ğŸ“ ë¶€ì¡± ì •ë³´: {eval_result.get('missing_info', 'N/A')}")
        print(f"ğŸ“ ì¶”ì²œ í‚¤ì›Œë“œ: {eval_result.get('recommended_keywords', 'N/A')}")
    
    print("="*60 + "\n")