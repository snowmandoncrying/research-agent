"""
Web Searcher Node
ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œ
"""

from ..research_state import ResearchState
from ..utils.search_client import get_tavily_client
from ..utils.domain_trust import get_domain_score

EXCLUDE_DOMAINS = [
    "kmong.com",
    "fiverr.com", 
    "coupang.com",
    "gmarket.co.kr",
    "11st.co.kr",
    "smartstore.naver.com",
    "auction.co.kr",
    "interpark.com",
]

def search_web(state: ResearchState) -> dict:
    """
    ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , ê´‘ê³  ë° ì‹ ë¢°ë„ê°€ ë‚®ì€ ì‚¬ì´íŠ¸ë¥¼ í•„í„°ë§
    1ë‹¨ê³„: Tavily APIì—ì„œ ê´‘ê³  ë„ë©”ì¸ ì œì™¸
    2ë‹¨ê³„: scoreë¡œ ì¶”ê°€ í•„í„°ë§
    """

    queries = state.get("search_queries", [])

    if not queries:
        print("[Web Searcher] ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {"search_results": state.get("search_results", [])}

    print(f"\n[Web Searcher] ì›¹ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘... ({len(queries)}ê°œ ì¿¼ë¦¬)")

    # Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    tavily = get_tavily_client()
    all_results = []
    filtered_count = 0

    for query in queries:
        print(f"  ğŸ” ê²€ìƒ‰: {query}")

        try:
            # Tavily ê²€ìƒ‰ ì‹¤í–‰ (1ì°¨)
            response = tavily.search(
                query=query,
                max_results=3,
                search_depth="advanced",
                exclude_domains=EXCLUDE_DOMAINS
            )

            # ê²°ê³¼ íŒŒì‹± (2ì°¨)
            for item in response.get("results", []):
                url = item.get("url", "")
                trust_score = get_domain_score(url)

                if trust_score <= 0.25:
                    filtered_count += 1
                    print(f"   âš ï¸ 2ì°¨ í•„í„°ë§: {url} (ì ìˆ˜: {trust_score})")
                    continue 

                all_results.append({
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "content": item.get("content", ""),
                    "trust_score": trust_score
                })

            total = len(response.get('results', []))
            collected = total - filtered_count
            print(f"    â†’ {total}ê°œ ê²€ìƒ‰, {collected}ê°œ ìˆ˜ì§‘, {filtered_count}ê°œ ì œì™¸")

        except Exception as e:
            print(f"    âš ï¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    # ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
    existing_results = state.get("search_results", [])
    raw_merged = existing_results + all_results
    unique_urls = {res['url'] : res for res in raw_merged}
    merged_results = list(unique_urls.values())
    merged_results.sort(key=lambda x: x.get("trust_score", 0), reverse=True)

    print(f"ì´ {len(merged_results)}ê°œ ê²€ìƒ‰ ê²°ê³¼ ì •ë ¬ ë° ë³‘í•© ì™„ë£Œ")

    return {
        "search_results": merged_results
    }

# ê²€ì¦í•˜ê¸°
if __name__ == "__main__":
    test_state = {
        "search_queries": [
            "ì¸ê³µì§€ëŠ¥ ì˜ë£Œ ì§„ë‹¨",
        ], 
        "search_results": [
          {
            "title": "ê¸°ì¡´ ìˆ˜ì§‘ëœ ì˜ë£Œ AI ë‰´ìŠ¤", 
            "url": "https://news.naver.com/ai-health", # ì´ ì£¼ì†Œì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ìš©
            "content": "ê¸°ì¡´ ë‚´ìš©...",
            "trust_score": 0.8
          }
        ]
    }
    final_state = search_web(test_state)
    results = final_state.get("search_results", [])

    print(f"ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: {len(results)}ê°œ")

    for num, res in enumerate(results, 1):
        print(f"\n{num}. [{res['trust_score']:.2f}] {res['title']}")
        print(f"   {res['url']}")